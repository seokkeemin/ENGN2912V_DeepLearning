{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967e5f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HW L4\n",
    "\n",
    "ENGN 2912V\n",
    "\n",
    "Seokkee Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "803f178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax.lax as jal\n",
    "from jax import jit, grad, vmap\n",
    "import time\n",
    "import sympy as sym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76ac4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Hardware:\n",
    "\n",
    "CPU: Intel i7-8750H @ 2.20GHz \n",
    "\n",
    "GPU: NVIDIA GeForce RTX 1060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd57a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define F(x) Function\n",
    "\n",
    "#jax function\n",
    "def fx(x):\n",
    "    sig = np.sqrt(0.2)\n",
    "    miu = 0\n",
    "    y = (1/(sig*jnp.sqrt(2*np.pi)))*jal.exp((-1/2)*(x-miu)**2/(sig)**2)    \n",
    "    return y\n",
    "\n",
    "# symbolic function and derivatives\n",
    "def fx_(x_):\n",
    "    sig = np.sqrt(0.2)\n",
    "    miu = 0\n",
    "    y_ = (1/(sig*sym.sqrt(2*np.pi)))*sym.exp((-1/2)*(x_-miu)**2/(sig)**2)    \n",
    "    dy = y_.diff(x_)\n",
    "    ddy = y_.diff(x_, x_)\n",
    "    dddy = y_.diff(x_, x_, x_)\n",
    "    return y_, dy, ddy, dddy\n",
    "    \n",
    "x_ = sym.symbols('x_')\n",
    "y_, dy, ddy, dddy = fx_(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa07a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 22:21:13.635856: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Define input variable X\n",
    "x = np.linspace(-5, 5, 10000, dtype=np.float64)\n",
    "x = jnp.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d580b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x10 Iteration Timing Function \n",
    "def looper(x, cpu, gpu):\n",
    "    t1 = np.zeros(10)\n",
    "    t2 = np.zeros(10)\n",
    "    t3 = np.zeros(10)\n",
    "    tc = np.zeros(10)\n",
    "    tg = np.zeros(10)\n",
    "    for i in range(10):\n",
    "        t1[i] = time.perf_counter()\n",
    "        vmap(cpu)(x)\n",
    "        t2[i] = time.perf_counter()\n",
    "        vmap(gpu)(x)\n",
    "        t3[i] = time.perf_counter()\n",
    "    \n",
    "    tc = t2-t1\n",
    "    tg = t3-t2\n",
    "    \n",
    "    return tc, tg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8614eb4",
   "metadata": {},
   "source": [
    "### 0-Order - f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6b1ea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unknown backend: 'gpu' requested, but no platforms that are instances of gpu are present. Platforms present are: interpreter,cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fx_gpu \u001b[38;5;241m=\u001b[39m jit(fx, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m fx_cpu \u001b[38;5;241m=\u001b[39m jit(fx, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m fx_g \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfx_gpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m fx_c \u001b[38;5;241m=\u001b[39m vmap(fx_cpu)(x)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m/gpfs/home/smin24/jax1.venv/lib/python3.11/site-packages/jax/_src/xla_bridge.py:381\u001b[0m, in \u001b[0;36mcanonicalize_platform\u001b[0;34m(platform)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m b\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown backend: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requested, but no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplatforms that are instances of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are present. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlatforms present are: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(b\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown backend: 'gpu' requested, but no platforms that are instances of gpu are present. Platforms present are: interpreter,cpu"
     ]
    }
   ],
   "source": [
    "fx_gpu = jit(fx, backend = 'gpu')\n",
    "fx_cpu = jit(fx, backend = 'cpu')\n",
    "fx_g = vmap(fx_gpu)(x)\n",
    "fx_c = vmap(fx_cpu)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc0, tg0 = looper(x, fx_cpu, fx_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1883fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Interations\n",
    "trial = np.linspace(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7867f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trial, tc0, 'r-o', label='CPU')\n",
    "plt.plot(trial, tg0, 'b-o', label='GPU')\n",
    "plt.legend()\n",
    "plt.xlabel('# of trials')\n",
    "plt.ylabel('Computation Time [s]')\n",
    "plt.title('F(x) Computation Time')\n",
    "plt.show()\n",
    "print('CPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc0), np.std(tc0)))\n",
    "print('GPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg0), np.std(tg0)))\n",
    "# print('CPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tc0[1:-1]), np.std(tc0[1:-1])))\n",
    "# print('GPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tg0[1:-1]), np.std(tg0[1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bed75",
   "metadata": {},
   "source": [
    "For the 0-order calculation, the GPU calculations generally appear to be slightly faster than the CPU. Both sets appear to be iterating faster overall as the number of iterations increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = [y_.subs({x_: point}) for point in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f711ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, fx_g, 'r-', label = \"JAX\")\n",
    "plt.plot(x, fa, 'k-.', label = \"SymPy\")\n",
    "plt.title('F(x)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b6fcf",
   "metadata": {},
   "source": [
    "Jax and SymPy representation of F(x) align."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc25bc1",
   "metadata": {},
   "source": [
    "### First Derivative - f'(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx_gpu = jit(grad(fx), backend = 'gpu')\n",
    "dfx_cpu = jit(grad(fx), backend = 'cpu')\n",
    "df_g = vmap(dfx_gpu)(x)\n",
    "df_c = vmap(dfx_cpu)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61aabf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc1, tg1 = looper(x, dfx_cpu, dfx_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trial, tc1, 'r-o', label='CPU')\n",
    "plt.plot(trial, tg1, 'b-o', label='GPU')\n",
    "plt.legend()\n",
    "plt.xlabel('# of trials')\n",
    "plt.ylabel('Computation Time [s]')\n",
    "plt.title('1st Derivative Computation Time')\n",
    "plt.show()\n",
    "print('CPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc1), np.std(tc1)))\n",
    "print('GPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg1), np.std(tg1)))\n",
    "# print('CPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tc1[1:-1]), np.std(tc1[1:-1])))\n",
    "# print('GPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tg1[1:-1]), np.std(tg1[1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784b5d6",
   "metadata": {},
   "source": [
    "For the first derivative of f(x), the CPU and GPU calculation times are approximately equal, with the GPU being slightly faster overall. The calculation time decreases overall as the number of trials increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = [dy.subs({x_: point}) for point in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, df_g, 'r-', label = \"JAX\")\n",
    "plt.plot(x, dfa, 'k-.', label = \"SymPy\")\n",
    "plt.title('1st Derivative')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b2698",
   "metadata": {},
   "source": [
    "Jax and SymPy representation of the 1st derivative of F(x) are in alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa877cd",
   "metadata": {},
   "source": [
    "### 2nd Derivative - f''(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jax\n",
    "ddfx_gpu = jit(grad(grad(fx)), backend = 'gpu')\n",
    "ddfx_cpu = jit(grad(grad(fx)), backend = 'cpu')\n",
    "\n",
    "ddf_g = vmap(ddfx_gpu)(x)\n",
    "ddf_c = vmap(ddfx_cpu)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit ddf_g.block_until_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation times\n",
    "tc2, tg2 = looper(x, ddfx_cpu, ddfx_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ad724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sympy substitution\n",
    "dy2_n = [ddy.subs({x_: point}) for point in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f165f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trial, tc2, 'r-o', label='CPU')\n",
    "plt.plot(trial, tg2, 'b-o', label='GPU')\n",
    "plt.legend()\n",
    "plt.xlabel('# of trials')\n",
    "plt.ylabel('Computation Time [s]')\n",
    "plt.title('2nd Derivative Computation Time')\n",
    "plt.show()\n",
    "print('CPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc2), np.std(tc2)))\n",
    "print('GPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg2), np.std(tg2)))\n",
    "# print('CPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tc2[1:-1]), np.std(tc2[1:-1])))\n",
    "# print('GPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tg2[1:-1]), np.std(tg2[1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c13cf",
   "metadata": {},
   "source": [
    "GPU calculations appear to be slightly faster than CPU calculations again, overall. Similar to the 1st derivative calculations, there appears to be a slight decrease in computation time as iterations increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, ddf_g, 'r-', label='GPU')\n",
    "plt.plot(x, dy2_n, 'k-.', label='SymPy')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('d2y/dx2')\n",
    "plt.title('2nd Derivative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df3698",
   "metadata": {},
   "source": [
    "Jax (GPU) and SymPy representations of the 2nd derivative of F(x) are in alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ac6d3",
   "metadata": {},
   "source": [
    "### 3rd Derivative - f'''(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jax\n",
    "dddfx_gpu = jit(grad(grad(grad(fx))), backend = 'gpu')\n",
    "dddfx_cpu = jit(grad(grad(grad(fx))), backend = 'cpu')\n",
    "\n",
    "dddf_g = vmap(dddfx_gpu)(x)\n",
    "dddf_c = vmap(dddfx_cpu)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29864199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit dddf_g.block_until_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation times\n",
    "tc3, tg3 = looper(x, dddfx_cpu, dddfx_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sympy substitution\n",
    "dy3_n = [dddy.subs({x_: point}) for point in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03116a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trial, tc3, 'r-o', label='CPU')\n",
    "plt.plot(trial, tg3, 'b-o', label='GPU')\n",
    "plt.legend()\n",
    "plt.xlabel('# of trials')\n",
    "plt.ylabel('Computation Time [s]')\n",
    "plt.title('3rd Derivative Computation Time')\n",
    "plt.show()\n",
    "print('CPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc3), np.std(tc3)))\n",
    "print('GPU Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg3), np.std(tg3)))\n",
    "# print('CPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tc2[1:-1]), np.std(tc2[1:-1])))\n",
    "# print('GPU Computation Time After 1st Iteration: mean = {} s, st.dev = {} s'.format(np.mean(tg2[1:-1]), np.std(tg2[1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178aa89",
   "metadata": {},
   "source": [
    "GPU calculations appear to be faster than the CPU calculations, yet again. Calculation time appears to decrease as the number of iterations increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, dddf_g, 'r-', label='GPU')\n",
    "plt.plot(x, dy3_n, 'k-.', label='SymPy')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('d^3y/dx^3')\n",
    "plt.title('3rd Derivative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26763e04",
   "metadata": {},
   "source": [
    "Jax (GPU) and SymPy representations of the 3rd derivative of F(x) are in alignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c55169",
   "metadata": {},
   "source": [
    "### Runtime vs Derivative Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0db57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "plt.plot(trial, tc0, 'k-o', label='0-order')\n",
    "plt.plot(trial, tc1, 'r-o', label='1st-order')\n",
    "plt.plot(trial, tc2, 'b-o', label='2nd-order')\n",
    "plt.plot(trial, tc3, 'm-o', label='3rd-order')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('# of trials')\n",
    "plt.ylabel('Computation Time [s]')\n",
    "plt.title('CPU Computation Time per Derivative Order')\n",
    "plt.show()\n",
    "\n",
    "print('CPU 0-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc0), np.std(tc0)))\n",
    "print('CPU 1st-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc1), np.std(tc1)))\n",
    "print('CPU 2nd-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc2), np.std(tc2)))\n",
    "print('CPU 3rd-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tc3), np.std(tc3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122c444",
   "metadata": {},
   "source": [
    "Looking at only the CPU calculation times, generally the time required appears to decrease as the number of iterations increase. This trend holds true for all of the derivative orders. There appears to be no particular relationship between calculation time and the order of the derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "plt.plot(trial, tg0, 'k-o', label='0-order')\n",
    "plt.plot(trial, tg1, 'r-o', label='1st-order')\n",
    "plt.plot(trial, tg2, 'b-o', label='2nd-order')\n",
    "plt.plot(trial, tg3, 'm-o', label='3rd-order')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('# of trials')\n",
    "plt.ylabel('Computation Time [s]')\n",
    "plt.title('GPU Computation Time per Derivative Order')\n",
    "plt.show()\n",
    "\n",
    "print('GPU 0-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg0), np.std(tg0)))\n",
    "print('GPU 1st-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg1), np.std(tg1)))\n",
    "print('GPU 2nd-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg2), np.std(tg2)))\n",
    "print('GPU 3rd-Order Computation Time: mean = {} s, st.dev = {} s'.format(np.mean(tg3), np.std(tg3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d756e20",
   "metadata": {},
   "source": [
    "For the GPU calculation times, generally the time required appears to decrease as the number of iterations increase. This trend holds true for all of the derivative orders. There appears to be no particular relationship between calculation time and the order of the derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2555ca",
   "metadata": {},
   "source": [
    "### time.performance_counter() vs %timeit\n",
    "Checking to see if the times results above are confounded with the time.performance_counter() api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b58b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU calculation times, in sequence of increasing order of derivative\n",
    "%timeit -n 1 -r 10 fx_c.block_until_ready\n",
    "%timeit -n 1 -r 10 df_c.block_until_ready\n",
    "%timeit -n 1 -r 10 ddf_c.block_until_ready\n",
    "%timeit -n 1 -r 10 dddf_c.block_until_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c079efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU calculation times, in sequence of increasing order of derivative\n",
    "%timeit -n 1 -r 10 fx_g.block_until_ready\n",
    "%timeit -n 1 -r 10 df_g.block_until_ready\n",
    "%timeit -n 1 -r 10 ddf_g.block_until_ready\n",
    "%timeit -n 1 -r 10 dddf_g.block_until_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17da6f",
   "metadata": {},
   "source": [
    "The %timeit api returns similar magnitude of calculation times for both CPU and GPU, on the order of a few hundred nanoseconds. This is ~10^4 magnitude faster than the previous method, of taking the difference between time.performance_counter() api time outputs before and after the calculation. \n",
    "\n",
    "As I wasn't able to get a number format (e.g. double, float, etc) output from the %timeit api, I wasn't able to replicate the calculation time vs iteration plots for it, and visually show whether or not the previous trend of the calculation time decrease per iteration also holds true for this api. However, as I increase the number of iterations, the average time does decrease so it stands to reason that there is a similar dependence on the number of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations increase per line\n",
    "%timeit -n 1 -r 1 dddf_g.block_until_ready\n",
    "%timeit -n 1 -r 2 dddf_g.block_until_ready\n",
    "%timeit -n 1 -r 5 dddf_g.block_until_ready\n",
    "%timeit -n 1 -r 10 dddf_g.block_until_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85335cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
